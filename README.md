# 웨이퍼 bin map 불량 타입 분류 모델 
- kaggle의 wm-811k Wafermap을 이용해 failure Type을 분류하는 모델을 만듬 
- 데이터 출처 : https://www.kaggle.com/ashishpatel26/wm-811k-wafermap

# 과정 순서 
1. 데이터 정제 및 분할
2. 데이터 모델링 

# 과정 별 진행 상세 
## 1. 웨이퍼 데이터 정제 [->코드 노트북](../wafer/wafer_data_preprocess.ipynb)
- wm-811k WaferMap은 약 81만 장의 wafer bin map 이미지와 웨이퍼 사이즈, failureType 등 으로 구성되어 있음 
- 이미지 사이즈 통일, failureType 코드화 전처리 진행 
- 전처리 된 데이터를 모델에 학습 시키려 했지만 용량이 너무 커 메모리 감당이 안됨 
- 그래서 웨이퍼 이미지 데이터를 분할 해 여러 pkl 파일로 저장 
- 모델링 파일을 따로 만들어 이미지 제너레이터 처럼 pkl 파일을 한개 씩 불러 와 학습 진행 
- 이 파일은 데이터 전처리와 분할까지의 과정 코드 
- **진행 중 애로사항**
  - 1. 너무 큰 용량 : 원 데이터 셋의 용량이 너무 커 메모리에 다 올리지 못해 분할하는 방식 채택 
  - 2. pkl 데이터 : 피클 데이터 로드 시 판다스를 사용, 판다스 특성 상 데이터를 최대 크기로 읽어 와 용량이 더 크게 잡힘 
  - 3. 리사이즈 : 처음에 사이즈가 다 다른 걸 모르고 그냥 진행, train데이터가 학습이 안됨, 추후에 사이즈가 다른 것을 발견하고 이를 통일하는 작업 진행 
  - 4. 분할 저장 : 정제된 데이터를 분할 저장 해 모델링 학습 시 분할 된 데이터를 한개 씩 가져와 학습하는 방식으로 진행 

## 2. 웨이퍼 모델링 [-> 코드 노트북](../wafer/wafer_modeling.ipynb)
- 웨이퍼 데이터 정제 파일에서 만든 pkl 파일을 이용해 모델 학습 진행 
- DNN 부터 CNN까지 요소를 한개씩 추가하며 acc를 비교 하여 CNN 모델을 만듬 
- **모델링 튜닝 과정**
  - 1. DNN 
  - 2. DNN + kernel Initializer
  - 3. DNN + Drop out 
  - 4. DNN + Regularization
  - 5. DNN + batch normalization 
  - 6. DNN + Batch normalization + Regularization 
  - 7. CNN
  - 8. CNN + Regularization 
  - 9. CNN + Batch_size 조정 
  - 10. CNN 2중 Conv 
  - 11. CNN 3중 Conv
  - 12. CNN 4중 Conv
  - 13. Cnn 5중 Conv
  - 14. CNN 6중 Conv -> 6중은 학습이 되지 않았음 
  - **CNN 5중 Conv 256 128 64 64 32 형태로 네트웤을 구성 했을 때 성능이 가장 좋았음** 
  - 이 형태로 제너레이터 적용해서 학습 진행 
 - normal 데이터를 제외한 0~7데이터만 이용 해 학습 진행 (상세 이유 : 아래 애로사항 참조)
 - 최종 성능 = acc : 0.87
 - 성능을 조금 더 높이기 위해 이미지를 회전 변형 진행 




- **진행 중 애로사항** 
  - y 값 Normalization 
    - 처음에 습관적으로 카테고리 y값에도 Normalization을 적용 해 학습 후 예측 결과가 이상하게 나옴, 이를 발견 후 0~8 원래 값으로 진행하여 정상적으로 작동 되는 것 확인 
  - normal 데이터로 인한 acc 착시 
    - 처음에 학습 시 0~8(8: normal 데이터)를 사용함, 하지만 8:normal 데이터의 양이 굉장히 많았고, normal을 판별하는 성능은 좋았기 때문에 전체적인 성능 역시 95%가 넘는 좋은 값을 보여 줌 
    - 하지만 이는 normal데이터로 인한 착시였고, normal 데이터를 제외 한 나머지 불량 데이터들의 failureType 판별은 성능은 좋지 않았음
    - 추 후 normal 데이터를 제외한 0~7까지의 데이터를 이용 해 학습을 진행했고 최종 성능은 약 acc 0.88정도가 나타남 
  - 이미지 회전 변형   
    - 최종 성능을 높이기 위해 이미지의 0도, 90도, 180도, 270도 이미지를 각각 만든 뒤, 이를 합침 
    - 합친 데이터를 이용 해 학습 진행
    - 하지만 성능 차이는 크지 않았음 
  - 오버피팅 
    - 샘플 데이터로 모델을 학습 해 성능비교를 했을 때는 오버 피팅 정도가 크지 않았음
    - 하지만 실 데이터로 학습 진행햇을 대는 오버 피팅 정도가 커졌음, 추후 다른 방법이 필요
  - 분할 데이터 학습 
    - 하나의 model = keras.Sequential()로 지정한 뒤 여러 데이터를 각각 불러와 model.fit()하는 방식으로 진행 했는데 이게 실질적으로 적용되엇는지 의문임    
